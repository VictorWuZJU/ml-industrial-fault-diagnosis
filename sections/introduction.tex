\section{Introduction}
\label{sec:introduction}

Unplanned faults in industrial assets such as rotating machinery, pumps, compressors, and production lines remain a major source of safety incidents, productivity loss, and maintenance costs. Fault detection and diagnosis (FDD) is therefore a central component of condition-based and predictive maintenance strategies in modern industrial plants. Classical approaches rely on analytical redundancy, observers, and rule-based expert systems, which in turn require accurate first-principles models and substantial domain expertise, and they often struggle with ageing equipment, variable operating conditions, and complex multi-component interactions~\cite{vashishtha2025roadmap,elbrawany2023survey}.

Over the past decade, the availability of high-resolution sensor data (vibration, current, temperature, pressure, acoustic) and the proliferation of industrial cyber-physical systems have driven a strong shift toward data-driven FDD based on machine learning (ML) and deep learning (DL). Recent reviews on mechanical and industrial systems report that ML- and DL-based methods can match or surpass traditional techniques for a wide range of tasks, from rolling bearing diagnosis to conveyor belts, gearboxes, and drive trains, while enabling richer multi-class discrimination and more flexible integration with Industrial Internet of Things (IIoT) infrastructures~\cite{zhao2025bearingreview,wang2025portapplications,montejano2025mlcomparison}. In parallel, survey work on industrial prognostics and health management (PHM) highlights the emergence of end-to-end data pipelines that integrate data acquisition, feature learning, model training, and deployment for diagnostics and prognostics in real production environments~\cite{souza2023pipeline,su2024phmreview,lei2025datadriven}.

At the same time, a rapidly growing body of work focuses on lightweight and edge-deployable diagnostic models. These include compact convolutional networks, transformers, and pruning/distillation-based architectures designed to run on resource-constrained platforms while preserving diagnostic accuracy~\cite{hou2024lightweighttransformer,gong2024resnet,jiang2024vmdshufflenet}. Such models are frequently evaluated on benchmark datasets such as CWRU or Paderborn and demonstrate promising performance for real-time or near-real-time diagnosis of rotating machinery. However, latency and computational budgets are often reported only as empirical measurements on a specific hardware configuration, and the connection between sampling period, windowing scheme, and worst-case inference time is rarely made explicit.

Beyond accuracy and latency, deployment of ML-based FDD in safety-critical or regulated environments raises questions of interpretability and trust. Recent surveys on explainable AI (XAI) for industrial FDD document increasing use of post-hoc attribution tools (e.g., SHAP, Grad-CAM) and local surrogate models, but also point out that explanations are often attached to particular model families and are not integrated with the decision logic or alarm thresholds used by operators~\cite{cacaco2025xai,maged2024xaireview}. Methodological work on XAI-based diagnosis in continuous processes has shown that model explanations can help identify root causes and multi-fault interactions, yet these studies typically target specific benchmark processes and do not formalize how explanations interact with real-time decision rules~\cite{jang2023xaiindustrial}.

In this context, several gaps remain. First, many studies describe the FDD pipeline informally, from sensor streams to model outputs, without a precise mathematical formulation of windowing, feature extraction, classifier mapping, and decision logic, which complicates systematic analysis under changes in sampling period, window length, or feature set~\cite{vashishtha2025roadmap,souza2023pipeline}. Second, real-time constraints—their relation to model complexity, stride, and hardware capability—are often handled as after-the-fact measurements rather than design constraints, even though they are critical in industrial adoption~\cite{hou2024lightweighttransformer,jiang2024vmdshufflenet}. Third, much of the literature is tied to a single dataset or rig, with tuning choices and thresholds that do not generalize easily across assets, despite evidence that field deployment demands cross-asset and cross-dataset robustness~\cite{montejano2025mlcomparison,lei2025datadriven}. Finally, while XAI has been proposed as a way to improve operator trust, current frameworks tend to focus on explaining model predictions in isolation rather than embedding explanations into the overall alarm and decision pipeline~\cite{cacaco2025xai,jang2023xaiindustrial}.

This work addresses these issues in the setting of machine-learning-based industrial fault diagnosis and real-time deployment. The contributions are threefold:

\begin{enumerate}
    \item \textbf{Unified mathematical formulation of the diagnosis pipeline.} We present a process-level model that formalizes the entire ML-based FDD chain, from multi-sensor time-series acquisition through sliding-window construction, feature extraction (handcrafted or learned), classifier mapping, and alarm logic. This formulation makes explicit how design choices such as sampling period, window length, stride, and feature dimension affect the mapping from sensor streams to fault labels and posterior confidence scores, and it is intended to complement recent review and roadmap work on industrial ML and PHM~\cite{vashishtha2025roadmap,zhao2025bearingreview,souza2023pipeline}.

    \item \textbf{Real-time streaming prediction algorithm with analyzable latency.} Building on this formulation, we derive a window-based streaming algorithm suitable for edge devices, together with a simple complexity and latency model that links feature-extraction cost, model inference cost, and sampling/stride parameters. This provides an explicit design condition for real-time feasibility (in terms of worst-case execution time per window) that can be evaluated on embedded or industrial PC platforms and is aligned with recent research on lightweight diagnostic networks and edge deployment~\cite{hou2024lightweighttransformer,gong2024resnet,jiang2024vmdshufflenet}.

    \item \textbf{Evaluation blueprint binding accuracy, latency, and deployment constraints.} We propose an evaluation protocol that combines public rotating-machinery datasets and plant data to assess both diagnostic performance (accuracy, confusion matrices, fault-wise metrics) and deployment-relevant metrics (latency, resource usage, stability of decision thresholds). The protocol is designed to sit between high-level comparative analyses of ML algorithms for FDD~\cite{montejano2025mlcomparison,lei2025datadriven} and practice-oriented XAI and deployment studies~\cite{cacaco2025xai,jang2023xaiindustrial}, and can be instantiated for different assets and sensing configurations.
\end{enumerate}

The goal is to provide a reusable but explicit framework that supports both theoretical analysis and practical implementation of ML-based industrial FDD, particularly in scenarios where real-time constraints, transparency, and cross-asset applicability are as relevant as raw classification accuracy (e.g., industrial pump, compressor, gearbox, conveyor).