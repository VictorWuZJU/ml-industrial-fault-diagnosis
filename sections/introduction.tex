\section{Introduction}
Unplanned faults in industrial assets such as rotating machinery, pumps, compressors, and production lines remain a major source of safety incidents, productivity loss, and maintenance costs. Fault detection and diagnosis (FDD) is therefore a central component of condition-based and predictive maintenance strategies in modern industrial plants. Classical approaches rely on analytical redundancy, observers, and rule-based expert systems, which in turn require accurate first-principles models and substantial domain ex- pertise, and they often struggle with ageing equipment, variable operating conditions, and complex multi-component interactions [1, 17].
Over the past decade, the availability of high-resolution sensor data (vi- bration, current, temperature, pressure, acoustic) and the proliferation of in- dustrial cyber-physical systems have driven a strong shift toward data-driven FDD based on machine learning (ML) and deep learning (DL). Recent re- views on mechanical and industrial systems report that ML- and DL-based methods can match or surpass traditional techniques for a wide range of tasks, from rolling bearing diagnosis to conveyor belts, gearboxes, and drive trains, while enabling richer multi-class discrimination and more flexible in- tegration with Industrial Internet of Things (IIoT) infrastructures [3, 4, 5]. In parallel, survey work on industrial prognostics and health management (PHM) highlights the emergence of end-to-end data pipelines that integrate data acquisition, feature learning, model training, and deployment for diag- nostics and prognostics in real production environments [6, 7, 8].
At the same time, a rapidly growing body of work focuses on lightweight and edge-deployable diagnostic models. These include compact convolu- tional networks, transformers, and pruning/distillation-based architectures designed to run on resource-constrained platforms while preserving diagnos- tic accuracy [9, 10, 11]. Such models are frequently evaluated on benchmark datasets such as CWRU or Paderborn and demonstrate promising perfor- mance for real-time or near-real-time diagnosis of rotating machinery. How- ever, latency and computational budgets are often reported only as empirical measurements on a specific hardware configuration, and the connection be- tween sampling period, windowing scheme, and worst-case inference time is rarely made explicit.
Beyond accuracy and latency, deployment of ML-based FDD in safety- critical or regulated environments raises questions of interpretability and trust. Recent surveys on explainable AI (XAI) for industrial FDD document


increasing use of post-hoc attribution tools (e.g., SHAP, Grad-CAM) and local surrogate models, but also point out that explanations are often at- tached to particular model families and are not integrated with the decision logic or alarm thresholds used by operators [12, 13]. Methodological work on XAI-based diagnosis in continuous processes has shown that model expla- nations can help identify root causes and multi-fault interactions, yet these studies typically target specific benchmark processes and do not formalize how explanations interact with real-time decision rules [14].
In this context, several gaps remain. First, many studies describe the FDD pipeline informally, from sensor streams to model outputs, without a precise mathematical formulation of windowing, feature extraction, classifier mapping, and decision logic, which complicates systematic analysis under changes in sampling period, window length, or feature set [1, 6]. Second, real-time constraints-their relation to model complexity, stride, and hardware capability-are often handled as after-the-fact measurements rather than de- sign constraints, even though they are critical in industrial adoption [9, 11]. Third, much of the literature is tied to a single dataset or rig, with tuning choices and thresholds that do not generalize easily across assets, despite evidence that field deployment demands cross-asset and cross-dataset ro- bustness [5, 7]. Finally, while XAI has been proposed as a way to improve operator trust, current frameworks tend to focus on explaining model predic- tions in isolation rather than embedding explanations into the overall alarm and decision pipeline [12, 14].
This work addresses these issues in the setting of machine-learning-based industrial fault diagnosis and real-time deployment. The contributions are threefold:
\begin{enumerate}
    \item Unified mathematical formulation of the diagnosis pipeline. We present a process-level model that formalizes the entire ML-based FDD chain, from multi-sensor time-series acquisition through sliding- window construction, feature extraction (handcrafted or learned), clas- sifier mapping, and alarm logic. This formulation makes explicit how design choices such as sampling period, window length, stride, and fea- ture dimension affect the mapping from sensor streams to fault labels and posterior confidence scores, and it is intended to complement recent review and roadmap work on industrial ML and PHM [1, 3, 8].
    \item Real-time streaming prediction algorithm with analyzable la- tency. Building on this formulation, we derive a window-based stream-
    
    ing algorithm suitable for edge devices, together with a simple complex- ity and latency model that links feature-extraction cost, model infer- ence cost, and sampling/stride parameters. This provides an explicit design condition for real-time feasibility (in terms of worst-case execu- tion time per window) that can be evaluated on embedded or industrial PC platforms and is aligned with recent research on lightweight diag- nostic networks and edge deployment [9, 10, 11].
    \item Evaluation blueprint binding accuracy, latency, and deploy- ment constraints. We propose an evaluation protocol that combines public rotating-machinery datasets and plant data to assess both diag- nostic performance (accuracy, confusion matrices, fault-wise metrics) and deployment-relevant metrics (latency, resource usage, stability of decision thresholds). The protocol is designed to sit between high-level comparative analyses of ML algorithms for FDD [5, 7] and practice- oriented XAI and deployment studies [12, 14], and can be instantiated for different assets and sensing configurations.
\end{enumerate}
The goal is to provide a reusable but explicit framework that supports both theoretical analysis and practical implementation of ML-based indus- trial FDD, particularly in scenarios where real-time constraints, transparency, and cross-asset applicability are as relevant as raw classification accuracy. (e.g., industrial pump, compressor, gearbox, conveyor).